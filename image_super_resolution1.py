# -*- coding: utf-8 -*-
"""Image super resolution.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qXEmuPEwoxfARQR2t64U-aWUB_hecnT6
"""

from google.colab import drive
drive.mount('/content/drive')

import re
import os
from scipy import ndimage, misc
from tqdm import tqdm
from tensorflow.keras.utils import img_to_array

from skimage.transform import resize, rescale
import matplotlib.pyplot as plt
import numpy as np
np.random.seed(0)

import cv2 as cv2
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout
from tensorflow.keras.layers import Conv2DTranspose, UpSampling2D, add, concatenate

from tensorflow.keras.models import Model
from tensorflow.keras import regularizers
from tensorflow.keras.utils import plot_model
import tensorflow as tf

def sorted_alphanumeric(data): 
    convert = lambda text: int(text) if text.isdigit() else text.lower()
    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]
    return sorted(data, key=alphanum_key)
SIZE = 256
high_img = []
path = '/content/drive/MyDrive/Image Super Resolution/dataset/Raw Data/high_res'
files = os.listdir(path)
files = sorted_alphanumeric(files)
for i in tqdm(files):
  if i == '855.jpg':
    break
  else:
    img = cv2.imread(path + '/'+i, 1)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img,(SIZE,SIZE))
    img = img.astype('float32')/ 255.0
    high_img.append(img_to_array(img))

high_img

low_img = []
path = '/content/drive/MyDrive/Image Super Resolution/dataset/Raw Data/low_res'
files = os.listdir(path)
files = sorted_alphanumeric(files)
for i in tqdm(files):
  if i == '855.jpg':
    break
  else:
    img = cv2.imread(path + '/'+i, 1)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img,(SIZE,SIZE))
    img = img.astype('float32')/ 255.0
    low_img.append(img_to_array(img))

low_img

# Define the mean and standard deviation of the noise
mean = 0
std_dev = 0.1

# for img in high_img:
#     # Add Gaussian noise to the image
#     noisy_img = img + np.random.normal(mean, std_dev, img.shape)

#     # Display original and noisy images
#     plt.figure(figsize = (10,10))
#     plt.subplot(1,2,1)
#     plt.title("Original Image", color = 'green', fontsize=15)
#     plt.imshow(img)
#     plt.axis('off')
#     plt.subplot(1,2,2)
#     plt.title("Noisy Image", color = 'black', fontsize=15)
#     plt.imshow(noisy_img)
#     plt.axis('off')
#     plt.show()


for i in range(4):
    # Add Gaussian noise to the high image
    noisy_high_img = high_img[i] + np.random.normal(mean, std_dev, high_img[i].shape)
    # Add Gaussian noise to the low image
    noisy_low_img = low_img[i] + np.random.normal(mean, std_dev, low_img[i].shape)

    # Display original and noisy images
    plt.figure(figsize = (10,10))
    plt.subplot(1,4,1)
    plt.title("Original High Image", color = 'green', fontsize=15)
    plt.imshow(high_img[i])
    plt.axis('off')
    plt.subplot(1,4,2)
    plt.title("Noisy High Image", color = 'black', fontsize=15)
    plt.imshow(noisy_high_img)
    plt.axis('off')
    plt.subplot(1,4,3)
    plt.title("Original Low Image", color = 'green', fontsize=15)
    plt.imshow(low_img[i])
    plt.axis('off')
    # plt.subplot(1,4,4)
    # plt.title("Noisy Low Image", color = 'black', fontsize=15)
    # plt.imshow(noisy_low_img)
    # plt.axis('off')
    plt.show()

noisy_high_img.shape

train_high_image = high_img[:500]
train_low_image = low_img[:500]
train_noisy_himage = noisy_high_img[:500]

train_high_image = np.reshape(train_high_image, (len(train_high_image), SIZE,SIZE,3))
train_low_image = np.reshape(train_low_image, (len(train_low_image), SIZE,SIZE,3))
#train_noisy_himage = np.reshape(train_noisy_himage, (len(train_noisy_himage), SIZE,SIZE,3))

print("shape of training high images:", train_high_image.shape)
print("shape of training low images:", train_low_image.shape )
print("shape of training noise high images:", train_noisy_himage.shape )

validation_high_image = high_img[500:830]
validation_low_image = low_img[500:830]
validation_high_image = np.reshape(validation_high_image, (len(validation_high_image), SIZE,SIZE,3))
validation_low_image = np.reshape(validation_low_image,(len(validation_low_image), SIZE,SIZE,3))

print("shape of validation of high images:", validation_high_image.shape)
print("shape of validation of low images:", validation_low_image.shape)

test_high_image = high_img[830:]
test_low_image = low_img[830:]
test_high_image = np.reshape(test_high_image, (len(test_high_image), SIZE,SIZE,3))
test_low_image = np.reshape(test_low_image, (len(test_low_image), SIZE,SIZE,3))

print("shape of test of high images:", test_high_image.shape)
print("shape of test of low images:", test_low_image.shape)

"""**MODEL BUILDING**"""

input_shape = Input(shape=(256,256,3))
batch_size = 1
kernel_size = 3
dropout = 0.4
n_filters = 64

def upsample_block(x, ch=256, k_s=3, st=1):
  x = tf.keras.layers.Conv2D(ch, k_s, strides =(st,st), padding = 'same')(x)
  x = tf.nn.depth_to_space(x,2)
  x = tf.keras.layers.LeakyReLU()(x)
  return x

left_inputs = Input(shape=(256,256,3))
x = left_inputs
filters = n_filters
for i in range(1):
  x = Conv2D(filters = n_filters, kernel_size= kernel_size, padding = 'same', activation = 'relu')(x)
  x = Dropout(dropout)(x)
  x = MaxPooling2D()(x)
  filters = filters

right_inputs = Input(shape = (256,256,3))
y = right_inputs
filters = n_filters 
for i in range(1):
  y = Conv2D(filters = n_filters, kernel_size = kernel_size, padding='same', activation = 'relu')(y)
  y = Dropout(dropout)(y)
  y = MaxPooling2D()(y)
  filetrs = filters


# right_inputs = Input(shape = (256,256,3))
# y = right_inputs
# filters = n_filters 
# for i in range(1):
#     y = Conv2D(filters = n_filters, kernel_size = kernel_size, padding='same', activation = 'relu')(y)
#     y = Dropout(dropout)(y)
#     y = MaxPooling2D()(y)
#     filters = filters // 2

y = add([x,y])

y = upsample_block(y)
outputs = Conv2D(3,(3,3), padding='same', activation= 'relu',activity_regularizer=regularizers.l1(10e-10))(y)

def upsample_block(x, ch=256, k_s=3, st=1):
    x = tf.keras.layers.Conv2D(ch, k_s, strides=(st,st), padding='same')(x)
    x = tf.nn.depth_to_space(x, 2)
    x = tf.keras.layers.LeakyReLU()(x)
    return x

left_inputs = Input(shape=(256,256,3))
x = left_inputs
filters = n_filters
for i in range(1):
    x = Conv2D(filters = n_filters, kernel_size= kernel_size, padding = 'same', activation = 'relu')(x)
    x = Dropout(dropout)(x)
    x = MaxPooling2D()(x)
    filters = filters // 2

right_inputs = Input(shape = (256,256,3))
y = right_inputs
filters = n_filters 
for i in range(1):
    y = Conv2D(filters = n_filters, kernel_size = kernel_size, padding='same', activation = 'relu')(y)
    y = Dropout(dropout)(y)
    y = MaxPooling2D()(y)
    filters = filters // 2

y = add([x,y])
y = upsample_block(y)
outputs = Conv2D(3,(3,3), padding='same', activation= 'relu', activity_regularizer=regularizers.l1(10e-10))(y)

model = Model(inputs=[left_inputs, right_inputs], outputs=outputs)
model.summary()

Multi_scale_learning= Model([left_inputs, right_inputs], outputs)
Multi_scale_learning.summary()
Multi_scale_learning.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = 'mean_absolute_error',
              metrics = ['acc'])
plot_model(Multi_scale_learning, to_file='Multi_scale_learning.png', show_shapes=True)

Multi_scale_learning.fit([train_low_image, train_low_image],
             train_high_image,
             validation_data=([validation_low_image, validation_low_image], validation_high_image),
             epochs=8,
             batch_size=batch_size)

def PSNR(y_true,y_pred):
    mse=tf.reduce_mean( (y_true - y_pred) ** 2 )
    return 20 * log10(1 / (mse ** 0.5))

def log10(x):
    numerator = tf.math.log(x)
    denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))
    return numerator / denominator

def pixel_MSE(y_true,y_pred):
    return tf.reduce_mean( (y_true - y_pred) ** 2 )

import tensorflow as tf
from tensorflow.keras import layers

def SRCNN():
    model = tf.keras.Sequential()
    model.add(layers.Conv2D(64, (9, 9), activation='relu', padding='same', input_shape=(None, None, 3)))
    model.add(layers.Conv2D(32, (1, 1), activation='relu', padding='same'))
    model.add(layers.Conv2D(3, (5, 5), activation='linear', padding='same'))
    return model

model = SRCNN()

def plot_images(high,low,predicted):
    plt.figure(figsize=(15,15))
    plt.subplot(1,3,1)
    plt.title('High Image', color = 'green', fontsize = 20)
    plt.imshow(high)
    plt.subplot(1,3,2)
    plt.title('Low Image ', color = 'black', fontsize = 20)
    plt.imshow(low)
    plt.subplot(1,3,3)
    plt.title('Predicted Image ', color = 'Red', fontsize = 20)
    plt.imshow(predicted)
   
    plt.show()

for i in range(10,20):
    
    predicted = np.clip(Multi_scale_learning.predict([test_low_image[i].reshape(1,SIZE, SIZE,3),test_low_image[i].reshape(1,SIZE, SIZE,3)]),0.0,1.0).reshape(SIZE, SIZE,3)
    plot_images(test_high_image[i],test_low_image[i],predicted)
    print('PSNR', PSNR(test_high_image[i],predicted))

# def plot_images(high,low,predicted):
#     plt.figure(figsize=(15,15))
#     plt.subplot(1,3,1)
#     plt.title('High Image', color = 'green', fontsize = 20)
#     plt.imshow(high)
#     plt.subplot(1,3,2)
#     plt.title('Low Image ', color = 'black', fontsize = 20)
#     plt.imshow(low)
#     plt.subplot(1,3,3)
#     plt.title('Predicted Image ', color = 'Red', fontsize = 20)
#     plt.imshow(predicted)
   
#     plt.show()

# for i in range(10,20):
    
#     predicted = np.clip(Multi_scale_learning.predict([test_low_image[i].reshape(1,SIZE, SIZE,3),test_low_image[i].reshape(1,SIZE, SIZE,3)]),0.0,1.0).reshape(SIZE, SIZE,3)
#     plot_images(test_high_image[i],test_low_image[i],predicted)
#     print('PSNR',SRCNN(test_high_image[i],predicted))

def downsample_image(image,scale):
    x=tf.image.resize(image / 255,(image.shape[0]//scale, image.shape[1]//scale))
    x=tf.image.resize(x,(image.shape[0], image.shape[1]), method = tf.image.ResizeMethod.BICUBIC)
    return x

def sorted_alphanumeric(data):  
    convert = lambda text: int(text) if text.isdigit() else text.lower()
    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]
    return sorted(data,key = alphanum_key)
# defining the size of the image
SIZE = 256
high_img = []
path = '/content/drive/MyDrive/Image Super Resolution/dataset/Raw Data/high_res'
files = os.listdir(path)
files = sorted_alphanumeric(files)
for i in tqdm(files):    
    if i == '5.png':
        break
    else:    
        img = cv2.imread(path + '/'+i,1)
        # open cv reads images in BGR format so we have to convert it to RGB
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        #resizing image
        img = cv2.resize(img, (SIZE, SIZE))
        img = img.astype('float32') / 255.0
        high_img.append(img_to_array(img))


low_img = []
path = '/content/drive/MyDrive/Image Super Resolution/dataset/Raw Data/low_res'
files = os.listdir(path)
files = sorted_alphanumeric(files)
for i in tqdm(files):
    if i == '5.png':
        break
    else: 
        img = cv2.imread(path + '/'+i,1)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        #img = downsample_image(img,4)
        #resizing image
        img = cv2.resize(img, (SIZE, SIZE))
        img = img.astype('float32') / 255.0
        #img = downsample_image(img,2)
        low_img.append(img_to_array(img))
        
sett_high_image = high_img[1:]
sett_low_image = low_img[1:]
sett_high_image= np.reshape(sett_high_image,(len(sett_high_image),SIZE, SIZE,3))
sett_low_image = np.reshape(sett_low_image,(len(sett_low_image),SIZE,SIZE,3))

def plot_images(high,low,predicted):
    plt.figure(figsize=(15,15))
    plt.subplot(1,3,1)
    plt.title('High Image', color = 'green', fontsize = 20)
    plt.imshow(high)
    plt.subplot(1,3,2)
    plt.title('Low Image ', color = 'black', fontsize = 20)
    plt.imshow(low)
    plt.subplot(1,3,3)
    plt.title('Predicted Image ', color = 'Red', fontsize = 20)
    plt.imshow(predicted)
   
    plt.show()

for i in range(0,4):
    
    predicted = np.clip(Multi_scale_learning.predict([sett_low_image[i].reshape(1,SIZE, SIZE,3),sett_low_image[i].reshape(1,SIZE, SIZE,3)]),0.0,1.0).reshape(SIZE, SIZE,3)
    plot_images(sett_high_image[i],sett_low_image[i],predicted)
    print('PSNR',PSNR(sett_high_image[i],predicted),'dB',"SSIM",tf.image.ssim(sett_high_image[i],predicted,max_val=1))

def plot_images(high,low,predicted):
    plt.figure(figsize=(15,15))
    plt.subplot(1,3,1)
    plt.title('High Image', color = 'green', fontsize = 20)
    plt.imshow(high)
    plt.subplot(1,3,2)
    plt.title('Low Image ', color = 'black', fontsize = 20)
    plt.imshow(low)
    plt.subplot(1,3,3)
    plt.title('Predicted Image ', color = 'Red', fontsize = 20)
    plt.imshow(predicted)
   
    plt.show()

for i in range(1,10):
    
    predicted = np.clip(model.predict(test_low_image[i].reshape(1,SIZE, SIZE,3)),0.0,1.0).reshape(SIZE, SIZE,3)
    plot_images(test_high_image[i],test_low_image[i],predicted)

import tensorflow as tf
from tensorflow import keras

# Define the model architecture
model = keras.Sequential()
model.add(keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=(SIZE, SIZE, 3)))
model.add(keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'))
model.add(keras.layers.UpSampling2D())
model.add(keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu'))
model.add(keras.layers.Conv2D(3, (3, 3), padding='same', activation='sigmoid'))

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model on the low resolution images and the corresponding high resolution images
model.fit(sett_low_image, sett_high_image, epochs=50, batch_size=32)

# Use the model to predict high resolution images from low resolution images
predicted_images = model.predict(sett_low_image)

# Plot the predicted high resolution images alongside the original high resolution images
for i in range(0,4):
    plot_images(sett_high_image[i], sett_low_image[i], predicted_images[i])
    print('PSNR', PSNR(sett_high_image[i], predicted_images[i]), 'dB', "SSIM", tf.image.ssim(sett_high_image[i], predicted_images[i], max_val=1))